# Concurrency benchmark config
# Based on EP-PBS 2P config, shortened for benchmarking
# Usage: cfr/scripts/benchmark_concurrent.py

system:
  recursion_limit: 10000

cfr_training:
  num_iterations: 80
  save_interval: 80
  pruning_enabled: true
  pruning_threshold: 1.0e-6
  exploitability_interval: 0
  num_workers: 1

cfr_plus_params:
  weighted_averaging_enabled: true
  averaging_delay: 0

cambia_rules:
  max_game_turns: 46
  cards_per_player: 4
  initial_view_count: 2
  cambia_allowed_round: 1
  allowDrawFromDiscardPile: true
  allowReplaceAbilities: true
  snapRace: false
  penaltyDrawCount: 2
  allowOpponentSnapping: true
  use_jokers: 2

agents:
  greedy_agent:
    cambia_call_threshold: 5

analysis:
  exploitability_num_workers: 0

deep_cfr:
  num_players: 2
  memory_archetype: "perfect"
  qre_lambda_start: 0.0
  hidden_dim: 256
  dropout: 0.1
  learning_rate: 0.001
  batch_size: 4096
  train_steps_per_iteration: 1000
  alpha: 1.5
  traversals_per_step: 333
  advantage_buffer_capacity: 2000000
  strategy_buffer_capacity: 2000000
  sampling_method: "outcome"
  engine_backend: "go"
  encoding_mode: "ep_pbs"
  pipeline_training: true
  use_residual: true
  num_hidden_layers: 3
  use_amp: false
  use_compile: false
  sd_cfr_mode: true
  sd_cfr_max_snapshots: 200
  max_tasks_per_child: "auto"
  worker_memory_budget_pct: 0.10
  enable_traversal_profiling: true
  profiling_jsonl_path: ""
  profile_step: 50

persistence:
  agent_data_save_path: ""
  checkpoint_save_interval: 80

logging:
  default_level: "WARNING"
  worker_config:
    default_level: "WARNING"
    sequential_rules: []
    overrides: []
  log_archive_enabled: false
  log_simulation_traces: false
